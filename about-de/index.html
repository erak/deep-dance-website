<!DOCTYPE html>
<html lang="en-us" class="bg-color">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta itemprop="name" content="About Deep.Dance">
<meta itemprop="description" content=""><meta property="og:title" content="About Deep.Dance" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://erak.github.io/deep-dance-website/about-de/" /><meta property="og:site_name" content="Deep.Dance" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="About Deep.Dance"/>
<meta name="twitter:description" content=""/>

	<link rel="apple-touch-icon" sizes="180x180" href="https://erak.github.io/deep-dance-website/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="https://erak.github.io/deep-dance-website/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="https://erak.github.io/deep-dance-website/favicon-16x16.png">
	<link rel="manifest" href="https://erak.github.io/deep-dance-website/site.webmanifest">
	<link rel="mask-icon" href="https://erak.github.io/deep-dance-website/safari-pinned-tab.svg" color="">
	<link rel="shortcut icon" href="https://erak.github.io/deep-dance-website/favicon.ico">

	<title>About Deep.Dance</title>
	<link rel="alternate" type="application/rss+xml" href="https://erak.github.io/deep-dance-website/about-de/index.xml" title="About Deep.Dance" />
	<link rel="stylesheet" href="https://erak.github.io/deep-dance-website/css/style.min.8b5b52baac4731ab813d4efe5cc1d334754c8ae37057aab3ab51f18a91d83017.css" integrity="sha256-i1tSuqxHMauBPU7+XMHTNHVMiuNwV6qzq1HxipHYMBc=" crossorigin="anonymous">
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-+0n0xVW2eSR5OomGNYDnhzAbDsOXxcvSN1TPprVMTNDbiYZCxYbOOl7+AMvyTG2x" crossorigin="anonymous">
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/js/bootstrap.bundle.min.js" integrity="sha384-gtEjrD/SeCtmISkJkNUaaKMoLD0//ElJ19smozuHV6z3Iehds+3Ulb9Bn9Plx0x4" crossorigin="anonymous"></script>
</head>

<body id="page">
	
    <div id="gallery">
        <div id="home-content" class="container">
            <h1 class="text-big"><a href="https://erak.github.io/deep-dance-website/#exhibits" class="back-link">←</a>About Deep.Dance</h1>
            <div class="content">
                <p><a href="https://erak.github.io/deep-dance-website/about">Auf Englisch lesen →</a></p>
<!-- <small> -->
<p>Drei Tänzer*innen begeben sich in eine hermetisch-sanfte Choreographie, die vollständig von einer künstlichen Intelligenz erstellt wurde, und erforschen die hyper-logische Kreativität von Code.</p>
<!-- </small> -->
<p>In deep.dance ersetzt ein Team aus internationalen Künslter*innen sich selbst durch eine künstliche Intelligenz. Eine vollständige Choreographie, kreiert durch ein von ihnen programmiertes, künstlich-neuronales Netz, wird bis ins Detail von drei Tänzer*innen ausgeführt. Die seltsam vertrauten  Bewegungen eröffnen einen emphatischen Blick in die hyper-logische Welt des Code. Dabei konfrontieren sie die Betrachter*innen mit einem Konstrukt, das wenigen Menschen zugänglich ist und trotzdem unsere Zukunft bestimmt.
Der Hamburger Choreograph Jascha Viehstädt entwirft eine stille und weiche Welt statistisch vorherbestimmter Bewegungen die spürbar macht, was es auslöst, menschliche Kreativität von einer Maschine berechnen zu lassen. Die strikte Einfachheit des Stücks bietet auf diese Weise einen Einblick in grundlegende Mechanismen von Software und Machine Learning und hinterfragt Hoffnungen und Ängste, die in die Entwicklung künstlicher Intelligenz projiziert werden.</p>
<h1 id="quicklinks">Quicklinks</h1>
<ul>
<li><a href="#starting-point">Starting Point →</a></li>
<li><a href="#k%C3%BCnstliche-intelligenz-ki">Künstliche Intelligenz (KI) →</a></li>
<li><a href="#ki-und-choreographie">KI und Choreographie →</a></li>
<li><a href="#kreativit%C3%A4t">Kreativität →</a></li>
<li><a href="#team">Team →</a></li>
<li><a href="#f%C3%B6rderer">Förderer →</a></li>
</ul>
<br/>
<br/>
<h1 id="starting-point">Starting Point</h1>
<p>Bereits in einigen seiner letzten Arbeiten und Kollaborationen beschäftigt sich der Hamburger Choreograph <a href="https://www.jaschaviehstaedt.com">Jascha Viehstädt -&gt;</a> mit dem Verhältniss zwischen Tanz, Technologie und Software. Unter anderem zusammen mit der <a href="http://www.costacompagnie.org">Costa Compagnie →</a>, dem Regisseur Felix Meyer-Christian und dem Medienkünstler und Programmierer Erik Kundt wurden mehrer Arbeiten innerhalb des Themenkomplexes realisiert. Dabei liegt das gemeinsame Interesse in der künstlerischen Untersuchung von globalen Transformations-Prozessen - solche, die das individuelle wie gesellschaftliche Leben stark beeinflussen und potentiell nachhaltig verändern.
Als 2018 das Stück OK, GOOGLE mit der Costa Compagnie entwickelt wurde, war das öffentliche Interesse an künstlicher Intelligenz gerade auf einem neuen Höhepunkt angelangt. Das Stück stellte den Sprachassistenten “Google Home”, welcher auf neuesten Entwicklungen im Bereich künstlicher Intelligenz von Google basierte, in den Mittelpunkt und entwarf eine Zukunftsvision realer und digitaler Performer*innen in gemeinsamer Symbiose. Mit der Aufmerksamkeit einer breiten Öffentlichkeit gehen viele Ängste, Hoffnungen und Vorurteile gegenüber KI einher. Den berechtigten Sorgen rund um übergreifende Computerisierung und undurchschaubare Komplexität in technologischer Entwicklung steht aber auch immer die sehr dynamische Vision gegenüber, ein Konstrukt zu schaffen, das eigenständig Denken und Handeln kann. Wobei diese Vision eher der Antrieb hinter heutiger Entwicklung und Wunschdenken ist, als das sie in absehbarer Zeit Realität werden würde.
Inspiration und Ausgangspunkt für Deep.Dance war der Wunsch, die Technologie und Entwicklung hinter dem Hype um “künstliche Intelligenz” zu erkunden und zu verstehen, wie sinnvoll, realistisch und wünschenswert ihr Einsatz in künstlerischer Arbeit ist. Damit einher geht die Frage nach der Kreativität an sich: Kann eine Software bzw. eine Maschine kreativ sein? Und wenn ja, was unterscheidet dann einen Menschen von einer Maschine oder einer Software?</p>
<h1 id="künstliche-intelligenz-ki">Künstliche Intelligenz (KI)</h1>
<p>Wenn es um das Thema der künstlichen Intelligenz geht, ist damit meistens Machine Learning gemeint. Vereinfacht gesagt ist das eine Technologie, die es ermöglicht Softwareprogramme durch Training statt ausschließlich durch konventionelles Programmieren zu erstellen. 
Üblicherweise besteht eine Software aus einer Reihe von Anweisungen (Algorithmus), die möglichst lückenlos die Schritte beschreiben, die ein Programm oder eine Maschine ausführen muss, um eine bestimmte Aufgabe zu erfüllen. Jeder einzelne Schritt wird beim konventionellen Programmieren von Menschen beschrieben. Moderne Software umfasst sehr komplexe und enorm viele dieser Anweisungen und baut deshalb meistens auf bereits bestehenden oder automatisch generierten Segmenten auf. Im Grunde aber ist tatsächlich jeder einzelne Schritt von Menschen gedacht und gebaut - und theoretisch logisch nachvollziehbar und erklärbar.</p>
<p>Beim maschinellen Lernen wird nur die Grundstruktur der Software von Menschen programmiert (z.B. ein künstliches neuronales Netz). Anschließend wird die Software mit Daten trainiert um die Funktionen selbständig zu “erlernen” die sie später ausführen soll. Wenn eine solche Software zum Beispiel Fotos von Katzen oder Hunden unterscheiden soll, wird sie mit einer großen Menge Bildern trainiert. Die Software rät zunächst völlig blind, welches der beiden Tiere auf einem Bild zu sehen ist und wird anschließend von einem Menschen korrigiert. Dieser Vorgang wird tausend-, wenn nicht millionenfach automatisiert wiederholt. Mit der Zeit lernt die Software, richtig zwischen Hund und Katze zu unterscheiden. Der entscheidende Unterschied zum konventionellen Programmieren ist, dass die Software nicht mit tausenden detaillierten Anweisungen programmiert wurde, die es dazu befähigen würde eine Katze von einem Hund zu unterscheiden. Stattdessen hat die Software nur anhand der Daten, die von Menschen korrekt bezeichnet waren, selber gelernt, das zu tun. Dabei bleibt uneinsichtig was genau die Software macht, um Motive auf den Bildern zu unterscheiden. Die Struktur, das neuronale Netzwerk, die noch von Menschen gebaut ist, verliert sich schnell durch verschachtelte und miteinander interagierenden Ebenen in einer unfassbaren Komplexität und Tiefe; daher auch der Begriff Deep Learning. Was genau im Inneren der Software passiert, bleibt eine Black-Box. 
Auch wenn die Funktionsweise einer KI auf logischen, mathematischen Prinzipien wie z.B. Wahrscheinlichkeitsrechnung basiert, sind die Entscheidungen mit steigender Komplexität der Aufgabe immer weniger für den menschlichen Verstand nachvollziehbar. Einfach aufgrund der schieren Datenmenge, mit der ein neuronales Netzwerke trainiert wird und der unvorstellbaren Geschwindigkeit mit der heutige Computer solche Datensätze verarbeiten können.</p>
<h1 id="ki-und-choreographie">KI und Choreographie</h1>
<p>Für Deep.Dance haben Erik Kundt, Nikolas Zöller und Lea Schörling ein solches neuronales Netzwerk programmiert (<a href="https://erak.github.io/deep-dance-website/code">mehr zu der Entwicklung der Software in Deep.Dance →</a>) und mit Bewegungsmaterial von 15 verschiedenen Tänzer*innen trainiert. Anschließend war das Netzwerk fähig über die Koordinaten mehrerer Keypoints eine Strichfigur im 3 Dimensionalen Raum zu bewegen: Für jeden Sekundenbruchteil machte das Netzwerk Prognosen für den folgenden Sekundenbruchteil, wie sich die Figur bzw. die Koordinaten der Keypoints am wahrscheinlichsten bewegen würde. Basierend auf dem gelernten Material, erschuf das Netzwerk so eine ca. 60-minütige Bewegungsstruktur (Auszüge einsehbar unter → AI Choreographie). Dabei ist die entstandene Choreographie keine einfache Neuformatierung des Trainingsmaterials, sondernd vielmehr eine errechnete Kombination bzw. ein Durchschnitt davon, kombiniert mit Prognosen zu sehr wahrscheinlichen Folgebewegungen. Das Material ähnelt zwar dem Trainingsmaterial, ist aber dennoch eine “neue” Kreation.</p>
<p>Die so entstandene Choreographie ist der Kernteil der Arbeit. Dabei haben wir versucht, so wenig Daten- bzw. Trainingsmaterial wie möglich zu verwenden und die von der KI generierten Bewegungen möglichst unbearbeitet zu lassen, um durch eine geringe Komplexität einen besseren Blick auf die Vorgänge und Funktionsweise in einer Software zu ermöglichen.</p>
<small>
Wie eine Partitur eines Musikstückes die von einem Orchester gespielt wird für die Zuhörer\*innen einen Blick in den Kopf der Komponistin\*in offenbart, so wirft Deep.Dance vor allem ein Licht auf das Innere einer Software und versucht der Zuschauer*in einen emphatischen Zugang zu ermöglichen.
</small>
<p>In der aktuellen Debatte um künstlichen Intelligenz (aber auch zur Technologie allgemein) verstellt die schiere Komplexität und Tiefe der Vorgänge meistens das tatsächliche Geschehen und lässt in diesem Falle den Mythos einer im menschlichen Sinne intelligenten, künstlichen Intelligenz entstehen. Einfach, weil es einfacher und faszinierender ist daran zu glauben, als Vorgänge nachvollziehbar zu machen oder nachzuvollziehen und sich mit den realen, viel vordringlicheren gesellschaftlichen Konsequenzen technologischer Entwicklung zu beschäftigen.</p>
<h1 id="kreativität">Kreativität</h1>
<p>Zusammenfassend fokussiert sich die Arbeit auf eine noch große Unbekannte in der Forschung an menschlicher Intelligenz und künstlich intelligenter Software: Die Kreativität. Was ist Kreativität und lässt sie sich mit Maschinen herstellen?
Deep.Dance konfrontiert uns, die Macher<em>innen, und alle kreativen Arbeiter</em>innen, mit den Fragen: Was geschieht, wenn die Choreograph*in nicht ein Mensch, sondern eine Software ist? Was bedeutet es, wenn wir dem vielleicht kreativen Prozess einer Maschine folgen und nicht umgekehrt? Und welcher Eindruck entsteht dabei für ein Publikum? Ist Kreativität nur eine sehr komplexe Ansammlung vieler, aber einfacher Daten?
Als eine Fallstudie am menschlichen Körper wollen wir herausfinden, was KI heute kann, ob sie sich in der Zukunft über das Erlernen oder Simulieren kreativer Prozesse tatsächlich unersetzbar machen könnte und ob wir willens sind oder es überhaupt sinnvoll ist, unsere kreativen und physikalischen Kapazitäten mit einer KI-Software zu teilen und uns derer unterzuordnen.</p>
<ul>
<li><a href="https://erak.github.io/deep-dance-website/code">Mehr zur Software Entwicklung von Deep.Dance →</a></li>
<li><a href="mailto:deepdance@jaschaviehstaedt.com">Kontakt →</a></li>
</ul>
<!-- <a href="https://erak.github.io/deep-dance-website/code">Read more about the coding</a>
<a href="https://erak.github.io/deep-dance-website/code" class="no-underline"> →</a> -->
<br/>
<br/>
<h1 id="team">Team</h1>
<h3 id="choreographie-brkünstlerische-leitung-produktionsleitung-br">Choreographie, <br/>Künstlerische Leitung, Produktionsleitung <br/></h3>
<ul>
<li><a href="http://www.jaschaviehstaedt.com">Jascha Viehstädt →</a></li>
</ul>
<h3 id="ki-entwicklungbr-coding-3d-design">KI Entwicklung<br/> Coding, 3D Design</h3>
<ul>
<li><a href="https://zirkular.io">Erik Kundt →</a></li>
<li>Lea Schorling</li>
</ul>
<h2 id="ki-entwicklung-coding">KI Entwicklung, Coding</h2>
<ul>
<li>Nikolas Zöller</li>
</ul>
<h3 id="tanz-kreation">Tanz, Kreation</h3>
<ul>
<li>Girish Kumar Rachappa</li>
<li>Lisa Rykena</li>
<li><a href="http://www.raymondliewjinpin.com">Raymond Liew Jin Pin →</a></li>
</ul>
<h3 id="bühne">Bühne</h3>
<ul>
<li><a href="https://www.takaya-kobayashi.de">Takaya Kobayashi →</a></li>
</ul>
<h3 id="outfit-3d-design">Outfit, 3D-Design</h3>
<ul>
<li>Mia Wittenhaus</li>
</ul>
<h3 id="dramaturgie">Dramaturgie</h3>
<ul>
<li><a href="http://www.costacompagnie.org">Felix Meyer-Christian →</a></li>
</ul>
<h3 id="outside-eye">Outside Eye</h3>
<ul>
<li><a href="http://www.chikakokaido.com/">Chikako Kaido →</a></li>
</ul>
<h3 id="graphik-design-pr">Graphik Design, PR</h3>
<ul>
<li>Julia Löffler</li>
<li>Lukas Besenfelder</li>
</ul>
<h3 id="video-editing">Video, Editing</h3>
<ul>
<li><a href="http://thomas-oswald.com/">Thomas Oswald →</a></li>
</ul>
<h3 id="photographie">Photographie</h3>
<ul>
<li><a href="https://www.marcusrenner.com/">Marcus Renner →</a></li>
</ul>
<h3 id="produktions-assistentin">Produktions Assistentin</h3>
<ul>
<li>Nika Viehstädt</li>
</ul>
<br/>
<br/>
<h1 id="förderer">Förderer</h1>
<ul>
<li><a href="https://www.fonds-daku.de/">Fonds Darstellende Künste AUTONOM →</a></li>
<li><a href="https://www.hamburg.de/bkm/">Behörde für Kultur und Medien Hamburg →</a></li>
<li><a href="https://www.kulturstiftung-hh.de/">Hamburgische Kulturstiftung →</a></li>
</ul>

                
            </div>
        </div>
        	<div id="footer" class="text-tiny">
		<a href="impress">Impress</a>
		|
		<a href="privacy">Privacy</a>
	</div>

    </div>
    


	<script src="https://erak.github.io/deep-dance-website/js/bundle.min.35ce9962c77e257c54debcf9189a0e9e112b43fe4d994ec9b19258640c69b764.js" integrity="sha256-Nc6ZYsd+JXxU3rz5GJoOnhErQ/5NmU7JsZJYZAxpt2Q=" crossorigin="anonymous"></script>
	
<script type="text/javascript">
    var _paq = window._paq || [];
     
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
      var u="//trace.fightforindependence.cc/";
      _paq.push(['setTrackerUrl', u+'matomo.php']);
      _paq.push(['setSiteId', '2']);
      var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
      g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
    })();
  </script>
  

</body>

</html>
